# pages/f1_news_scraper.py

import streamlit as st
from datetime import datetime, timedelta
from scraper import fetch_recent_news
from rag import get_vector_store, update_db_with_news

st.set_page_config(
    page_title=" Scrapeo y Resumen de Noticias"
)

st.title(" Scrapeo y Resumen de Noticias F1 (Beta)")
st.caption("Obtenci贸n de datos reales (simulada) de sitios web, resumen con Gemini, e indexaci贸n en FAISS.")
st.markdown("---")

st.header("1. Configuraci贸n de Scrapeo")

# --- Control de Fecha ---
default_date = datetime.today() - timedelta(days=7) # Por defecto, la 煤ltima semana
start_date = st.date_input(
    "Fecha M铆nima de Publicaci贸n",
    value=default_date,
    help="Solo se indexar谩n art铆culos publicados a partir de esta fecha."
)
start_datetime = datetime(start_date.year, start_date.month, start_date.day)

# --- Bot贸n de Ejecuci贸n ---
if st.button(" Iniciar Web Scraping y Resumen (Usando Gemini)",
             type="primary", use_container_width=True):

    # 1. Obtener la base de datos
    vector_store = get_vector_store()

    st.subheader("2. Proceso en Curso...")

    # 2. Ejecutar el scraping
    with st.status("Iniciando proceso de Scrapeo y Resumen...", expanded=True) as status:
        st.write(f"Buscando noticias desde: **{start_date.strftime('%Y-%m-%d')}**")

        try:
            # fetch_recent_news tiene l贸gica de MOCK/seguridad para evitar bloqueos de IP            
            new_data = fetch_recent_news(start_datetime)

            if new_data:
                st.success(f" Se encontraron y procesaron {len(new_data)} art铆culos.")

                # 3. Indexaci贸n en FAISS (Llamada al m贸dulo rag.py)
                status.update(label="Indexando nuevos res煤menes en FAISS...", state="running", expanded=True)

                # Aqu铆 llamamos directamente a la l贸gica de indexaci贸n de rag.py
                update_db_with_news(vector_store, new_data)

                # 4. Mostrar Resultados
                st.subheader("3. Res煤menes Indexados:")
                for item in new_data:
                    st.code(f"[{item['driver']} | {item['source']}]: {item['content']}", language="markdown")

                status.update(label="Proceso de Scrapeo e Indexaci贸n completo.", state="complete", expanded=False)
            else:
                st.warning("No se encontraron nuevos art铆culos o el scrapeo fue bloqueado. Intenta cambiar la fecha o las fuentes.")
                status.update(label="Proceso finalizado sin resultados.", state="complete", expanded=False)

        except Exception as e:
            st.error(f"Fallo cr铆tico en el proceso de scraping/LLM: {e}")
            status.update(label="Proceso Fallido.", state="error")
